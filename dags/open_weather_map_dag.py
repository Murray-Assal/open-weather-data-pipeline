from airflow.sdk import task, dag
from airflow.providers.http.hooks.http import HttpHook
from airflow.providers.databricks.hooks.databricks_sql import DatabricksSqlHook as sql
from datetime import datetime, timedelta
import os
import pandas as pd
import logging

lat=30.044420 # Latitude for Cairo, Egypt
lon=31.235712 # Longitude for Cairo, Egypt
api_key=os.getenv('OPEN_WEATHER_MAP_API_KEY') # Replace with your OpenWeatherMap API key

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 0,
    'retry_delay': timedelta(seconds=10),
}
@dag(
    dag_id='open_weather_map_dag',
    default_args=default_args,
    description='A DAG to fetch weather data from OpenWeatherMap API and store it in PostgreSQL',
    schedule= None, #External trigger only
    start_date=datetime(2025, 10, 28),
    catchup=False,
)
def open_weather_map_dag():

    @task()
    def extract_weather_data():
        '''
        Extract weather data from OpenWeatherMap API for the specified location for the last 5 days.
        The input data should look similar to this:
        {
            "lat": 30.0444,
            "lon": 31.2357,
            "timezone": "Africa/Cairo",
            "timezone_offset": 7200,
            "data":
            [
                {
                    "dt": 1622505600,
                    "sunrise": 1622516073,
                    "sunset": 1622566295,
                    "temp": 22.52,
                    "feels_like": 22.29,
                    "pressure": 1011,
                    "humidity": 56,
                    "dew_point": 13.31,
                    "clouds": 0,
                    "visibility": 6000,
                    "wind_speed": 5.66,
                    "wind_deg": 20,
                    "weather": [
                        {
                            "id": 800,
                            "main": "Clear",
                            "description": "clear sky",
                            "icon": "01n"
                        }
                    ]
                }
            ]
        }
        '''
        http_hook = HttpHook(method='GET', http_conn_id='open_weather_map_api')
        weather_data = []
        start_date = datetime.now() - timedelta(days=5)
        end_date = datetime.now()
        delta = timedelta(days=1)
        date_in_loop = start_date
        while date_in_loop <= end_date:
            timestamp = int(date_in_loop.timestamp())
            endpoint = f'/data/3.0/onecall/timemachine?lat={lat}&lon={lon}&dt={timestamp}&appid={api_key}&units=metric'
            response = http_hook.run(endpoint)
            if response.status_code == 200:
                data = response.json()
                weather_data.append(data)
                logger.info(f"Extracted weather data for {date_in_loop.strftime('%Y-%m-%d')}")
            else:
                logger.error(f"Failed to fetch data for {date_in_loop.strftime('%Y-%m-%d')}: {response.text}")
                raise Exception("API request failed")
            date_in_loop += delta
        return weather_data

    
    @task()
    def transform_weather_data(weather_data):
        # Transform the extracted data into a pandas DataFrame
        records = []
        for entry in weather_data:
            record = {
                'timezone': entry['timezone'],
                'sunrise': datetime.fromtimestamp(entry['data'][0]['sunrise']),
                'sunset': datetime.fromtimestamp(entry['data'][0]['sunset']),
                'temp': entry['data'][0]['temp'],
                'feels_like': entry['data'][0]['feels_like'],
                'pressure': entry['data'][0]['pressure'],
                'humidity': entry['data'][0]['humidity'],
                'dew_point': entry['data'][0]['dew_point'],
                'clouds': entry['data'][0]['clouds'],
                'visibility': entry['data'][0]['visibility'],
                'wind_speed': entry['data'][0]['wind_speed'],
                'wind_deg': entry['data'][0]['wind_deg'],
                'sky': entry['data'][0]['weather'][0]['description']
            }
            records.append(record)
        return records
    
    @task()
    def load_weather_data(transformed_data):
        # Load the transformed data into Databricks Warehouse
        df = pd.DataFrame(transformed_data)
        databricks_hook = sql(databricks_conn_id="databricks_default", schema="default")
        with databricks_hook.get_conn() as conn:
            cursor = conn.cursor()
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS raw.default.cairo_weather_data (
            id BIGINT GENERATED BY DEFAULT AS IDENTITY,
            timezone VARCHAR(50),
            sunrise TIMESTAMP,
            sunset TIMESTAMP,
            temp FLOAT,
            feels_like FLOAT,
            pressure INT,
            humidity INT,
            dew_point FLOAT,
            clouds INT,
            visibility INT,
            wind_speed FLOAT,
            wind_deg INT,
            sky VARCHAR(100)
            );
        ''')
            for _, row in df.iterrows():
                cursor.execute(f"""
                    INSERT INTO raw.default.cairo_weather_data (
                        timezone, sunrise, sunset, temp, feels_like, pressure, humidity,
                        dew_point, clouds, visibility, wind_speed, wind_deg, sky
                    ) VALUES (
                        '{row['timezone']}','{row['sunrise']}','{row['sunset']}',{row['temp']},{row['feels_like']},{row['pressure']},{row['humidity']},
                        {row['dew_point']},{row['clouds']},{row['visibility']},{row['wind_speed']},{row['wind_deg']},'{row['sky']}'
                    )
                """)
        cursor.close()
        conn.close()

    weather_data = extract_weather_data()
    transformed_data = transform_weather_data(weather_data)
    load_weather_data(transformed_data)
open_weather_map_dag = open_weather_map_dag()
